# ğŸš€ Chat-to-3D All-in-One Docker

**Tek bir Docker container'da tÃ¼m servisler!**

Bu Ã§Ã¶zÃ¼m, Chat-to-3D projesinin tÃ¼m bileÅŸenlerini (LLM, TRELLIS 3D generation, ve Gradio UI) tek bir container iÃ§inde Ã§alÄ±ÅŸtÄ±rÄ±r.

## ğŸŒŸ Ã–zellikler

- âœ… **Tek Container**: TÃ¼m servisler tek container'da
- âœ… **Basit Kurulum**: Sadece `./install.sh`
- âœ… **DÃ¼ÅŸÃ¼k Kaynak**: NIM container'larÄ± yerine yerel Python
- âœ… **Supervisor**: TÃ¼m servisler otomatik yÃ¶netilir
- âœ… **GPU HÄ±zlandÄ±rma**: CUDA desteÄŸi ile hÄ±zlÄ± Ã§alÄ±ÅŸma

## ğŸ¯ NIM Container vs All-in-One

| Ã–zellik          | NIM Containers | All-in-One     |
| ---------------- | -------------- | -------------- |
| Container SayÄ±sÄ± | 3 ayrÄ±         | 1 tek          |
| Bellek KullanÄ±mÄ± | ~20-30GB       | ~10-15GB       |
| Kurulum SÃ¼resi   | 60-120 dakika  | 30-60 dakika   |
| NGC API Key      | Gerekli        | Gerekmez       |
| BaÅŸlatma SÃ¼resi  | 5-10 dakika    | 2-3 dakika     |
| YÃ¶netim          | Docker Compose | Docker Compose |

## ğŸ“‹ Gereksinimler

- Docker 20.10+
- Docker Compose v2.0+
- NVIDIA Container Toolkit
- NVIDIA GPU (16GB+ VRAM Ã¶nerilir)
- 50GB+ disk alanÄ±

### NVIDIA Container Toolkit Kurulumu

```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Kurulum

```bash
cd allinone
chmod +x install.sh
./install.sh
```

### 2. KullanÄ±m

TarayÄ±cÄ±nÄ±zda aÃ§Ä±n: http://localhost:7860

## ğŸ“¦ Manuel Kurulum

```bash
# .env dosyasÄ±nÄ± oluÅŸtur (opsiyonel)
cp .env.example .env
nano .env  # HF_TOKEN ekle (opsiyonel)

# Container'Ä± build et ve baÅŸlat
docker compose build
docker compose up -d

# LoglarÄ± izle
docker compose logs -f
```

## ğŸ”§ YÃ¶netim KomutlarÄ±

```bash
# Container'Ä± baÅŸlat
docker compose up -d

# Container'Ä± durdur
docker compose down

# LoglarÄ± gÃ¶rÃ¼ntÃ¼le
docker compose logs -f

# Servis loglarÄ±nÄ± ayrÄ± ayrÄ± gÃ¶rÃ¼ntÃ¼le
docker compose exec chat-to-3d-allinone tail -f /var/log/supervisor/llm-service.out.log
docker compose exec chat-to-3d-allinone tail -f /var/log/supervisor/trellis-service.out.log
docker compose exec chat-to-3d-allinone tail -f /var/log/supervisor/gradio-app.out.log

# Container iÃ§ine gir
docker compose exec chat-to-3d-allinone bash

# Servisleri yeniden baÅŸlat (container iÃ§inde)
docker compose exec chat-to-3d-allinone supervisorctl restart all

# Container'Ä± yeniden baÅŸlat
docker compose restart

# TÃ¼m verileri sil
docker compose down -v
```

## ğŸ—ï¸ Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     All-in-One Docker Container         â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚        Supervisor                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚          â”‚          â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LLM Serviceâ”‚ â”‚ TRELLIS  â”‚ â”‚ Gradio â”‚ â”‚
â”‚  â”‚ Port: 19002â”‚ â”‚Port: 8000â”‚ â”‚Port:   â”‚ â”‚
â”‚  â”‚ (internal) â”‚ â”‚(internal)â”‚ â”‚7860    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â””â”€â”€â”€ Port 7860 (Exposed)
```

### Servis DetaylarÄ±

**Supervisor**: TÃ¼m servisleri yÃ¶netir

- Servisleri otomatik baÅŸlatÄ±r
- Ã‡Ã¶kme durumunda yeniden baÅŸlatÄ±r
- Log yÃ¶netimi yapar

**LLM Service** (Port 19002, internal):

- Transformers tabanlÄ± LLM
- OpenAI-compatible API
- Llama 3.1 veya Llama 2 fallback

**TRELLIS Service** (Port 8000, internal):

- 3D model generation
- Image-to-3D pipeline
- GLB format export

**Gradio App** (Port 7860, exposed):

- Web UI
- Ä°ki servisi kullanÄ±r
- KullanÄ±cÄ± arayÃ¼zÃ¼

## ğŸ” Sorun Giderme

### Container baÅŸlamÄ±yor?

```bash
# LoglarÄ± kontrol et
docker compose logs -f

# Belirli bir servisin loglarÄ±
docker compose exec chat-to-3d-allinone tail -f /var/log/supervisor/llm-service.err.log
```

### GPU tanÄ±nmÄ±yor?

```bash
# GPU eriÅŸimini test et
docker run --rm --gpus all nvidia/cuda:12.8.1-base-ubuntu22.04 nvidia-smi

# Container iÃ§inde GPU kontrolÃ¼
docker compose exec chat-to-3d-allinone nvidia-smi
```

### Model yÃ¼kleme hatalarÄ±?

Hugging Face token gerekli olabilir (Llama modelleri iÃ§in):

1. https://huggingface.co/settings/tokens adresinden token alÄ±n
2. `.env` dosyasÄ±na ekleyin: `HF_TOKEN=your_token_here`
3. Container'Ä± yeniden baÅŸlatÄ±n: `docker compose restart`

### Bellek yetersizliÄŸi?

`docker-compose.yml` dosyasÄ±nda `shm_size` deÄŸerini artÄ±rÄ±n:

```yaml
shm_size: 32gb # VarsayÄ±lan: 16gb
```

### Servisler birbirini bulamÄ±yor?

Container iÃ§inde servislerin durumunu kontrol edin:

```bash
docker compose exec chat-to-3d-allinone supervisorctl status
```

Servisleri yeniden baÅŸlatÄ±n:

```bash
docker compose exec chat-to-3d-allinone supervisorctl restart all
```

## ğŸ“Š Performans

- **Ä°lk BaÅŸlatma**: 30-60 dakika (model indirme)
- **Sonraki BaÅŸlatmalar**: 2-3 dakika
- **GPU BelleÄŸi**: 10-15GB
- **Disk KullanÄ±mÄ±**: ~50GB (modellerle)

## ğŸ”„ GÃ¼ncelleme

```bash
# En son kodu Ã§ek
git pull

# Container'Ä± yeniden build et
docker compose build --no-cache

# Yeniden baÅŸlat
docker compose up -d
```

## ğŸ†š Ana Docker Compose ile KarÅŸÄ±laÅŸtÄ±rma

### All-in-One AvantajlarÄ±:

- âœ… Daha basit yapÄ±
- âœ… Daha az bellek kullanÄ±mÄ±
- âœ… Daha hÄ±zlÄ± baÅŸlatma
- âœ… NGC API key gerekmez
- âœ… Daha kolay debug

### Ana Docker Compose AvantajlarÄ±:

- âœ… NVIDIA NIM optimizasyonlarÄ±
- âœ… Daha iyi performans (bazÄ± durumlarda)
- âœ… Servisler baÄŸÄ±msÄ±z Ã¶lÃ§eklenebilir
- âœ… Resmi NVIDIA imajlarÄ±

## ğŸ“ Notlar

- Ä°lk Ã§alÄ±ÅŸtÄ±rmada modeller indirilir
- Modeller cache'lenir, sonraki baÅŸlatmalar hÄ±zlÄ±dÄ±r
- TÃ¼m veriler Docker volume'larÄ±nda saklanÄ±r
- `.env` dosyanÄ±zÄ± git'e commit etmeyin

## ğŸ› Sorun Bildirme

Sorun yaÅŸarsanÄ±z, lÃ¼tfen ÅŸu bilgileri toplayÄ±n:

```bash
# Sistem bilgileri
docker version
docker compose version
nvidia-smi

# Container loglarÄ±
docker compose logs > logs.txt

# Supervisor durumu
docker compose exec chat-to-3d-allinone supervisorctl status
```

## ğŸ“„ Lisans

Apache 2.0 License - Detaylar iÃ§in LICENSE dosyasÄ±na bakÄ±nÄ±z.

---

**HazÄ±r mÄ±sÄ±nÄ±z?** Hemen baÅŸlayÄ±n: `./install.sh` ğŸš€
